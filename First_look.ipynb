{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d424d16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:48:43.882745Z",
     "start_time": "2025-12-04T23:48:43.784159Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"pastel\")\n",
    "from scipy import stats\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "csv_path = Path(\"data\") / \"train_merged.csv\"\n",
    "# csv_path = os.path.join(\"data\", \"train_merged.csv\")   os ile alternatif..\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(str(Path.cwd() / 'functions'))\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa1b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.titleweight'] = 'bold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901989b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:49:36.702319Z",
     "start_time": "2025-12-04T23:48:46.688541Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path, low_memory=False)\n",
    "print(df.shape)\n",
    "# display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024f1e15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:50:50.054613Z",
     "start_time": "2025-12-04T23:50:34.482867Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = reduce_mem_usage(df.copy())\n",
    "\n",
    "categorical_features = [\n",
    "    'ProductCD', 'P_emaildomain', 'R_emaildomain','DeviceType', 'DeviceInfo',\n",
    "    'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n",
    "    'addr1', 'addr2',\n",
    "    'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9',\n",
    "    'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20',\n",
    "    'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30',\n",
    "    'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38'\n",
    "]\n",
    "numerical_features = [col for col in train_df.columns if col not in categorical_features]\n",
    "\n",
    "resumetable(train_df[categorical_features])[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a519a",
   "metadata": {},
   "source": [
    "Entropy : \n",
    "    --> Measures the uncertainty or randomness of the data distribution in each column, using Shannon entropy. It quantifies how evenly the values are spread.\n",
    "\n",
    "> **High entropy** (closer to log2 of unique values): Values are diverse and evenly distributed (e.g., many unique categories with similar frequencies).\n",
    "\n",
    "> **Low entropy** (closer to 0): Values are concentrated (e.g., mostly one value or few dominant ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35979eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:52:56.914951Z",
     "start_time": "2025-12-04T23:52:54.409482Z"
    }
   },
   "outputs": [],
   "source": [
    "top_missing_cols(train_df, thresh=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a6b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 95\n",
    "high_missing = top_missing_cols(train_df, thresh=90)\n",
    "cols_to_drop = high_missing[high_missing['missing_percent'] > threshold]['col'].tolist()\n",
    "\n",
    "train_df = train_df.drop(columns=cols_to_drop)\n",
    "print(f\" {threshold}% üstü eksik olan {len(cols_to_drop)} sütun silindi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b592d3",
   "metadata": {},
   "source": [
    "Bazı değişkenlerin %99 dan fazlasının eksik olduğu görülüyor. Bu değişkenlerden gelen bilgilerin modelin genelleme yeteneğini kötü etkileyeceğini düşünüyoruz.\n",
    "\n",
    "Çok fazla eksik değere sahip olan özellikleri siliyoruz. Threshold belirlerken hedefteki oranın fazla değişmemesine dikkat ediyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6368003",
   "metadata": {},
   "source": [
    "### Target Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcfb69e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:53:04.209421Z",
     "start_time": "2025-12-04T23:53:03.626074Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Class distribution for 'isFraud':\")\n",
    "print(train_df['isFraud'].value_counts())\n",
    "print(\"\\nPercentage:\")\n",
    "print(train_df['isFraud'].value_counts(normalize=True))\n",
    "\n",
    "counts = train_df['isFraud'].value_counts()\n",
    "percentages = train_df['isFraud'].value_counts(normalize=True) * 100\n",
    "\n",
    "colors = ['green', 'red'] \n",
    "bars = plt.bar(counts.index, counts.values, color=colors[:len(counts)])\n",
    "\n",
    "plt.title('isFraud Class Distribution')\n",
    "plt.xlabel('isFraud')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1])\n",
    "\n",
    "for bar, perc in zip(bars, percentages):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.05, f'{perc:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17eba6",
   "metadata": {},
   "source": [
    "# Categorical Features Analysis\n",
    "\n",
    "Hedef değişkenin dengesiz olduğu görülmektedir. Bu nedenle modelleme aşamasında undersampling, oversampling veya sınıf ağırlıklarının ayarlanması gibi stratejiler değerlendirilebilir.\n",
    "\n",
    "Kategorik özelliklerin tamamı analize uygun değildir. Bazı değişkenler yüksek kardinalite içerdiğinden doğrudan kategorik inceleme anlamlı sonuç vermemektedir. Bu nedenle kardinalitesi makul seviyede olan değişkenler ayrıştırılarak hedef değişkenle ilişkileri incelenmiştir.\n",
    "\n",
    "Amaç, belirli kategorilerin bulunması veya belirli değerlerin gözlenmesi durumunda isFraud oranında kayda değer bir değişiklik olup olmadığını belirlemektir. Böyle bir ilişki tespit edilirse veri ön işleme aşamasında uygun dönüşümler yapılabilir.\n",
    "\n",
    "Kategorik Özellikler\n",
    "\n",
    "Transaction verileri:\n",
    "\n",
    "ProductCD: İşlem ürün kodu.\n",
    "\n",
    "card1–card6: Kart tipi, kart ülkesi vb. kart bilgileri.\n",
    "\n",
    "addr1, addr2: Coğrafi adres bilgisi.\n",
    "\n",
    "P_emaildomain: Alıcı/purchaser e-posta alan adı.\n",
    "\n",
    "R_emaildomain: Gönderici/recipient e-posta alan adı.\n",
    "\n",
    "M1–M9: Eşleşme durumları (kart sahibi–adres uyumu vb.)\n",
    "\n",
    "Identity verileri:\n",
    "\n",
    "DeviceType: İşlemde kullanılan cihaz türü.\n",
    "\n",
    "DeviceInfo: Cihaz bilgisi (model, üretici vb.)\n",
    "\n",
    "id_12–id_38: Ağ bağlantısı, tarayıcı bilgileri ve çeşitli oturum nitelikleri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd781755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:53:23.975574Z",
     "start_time": "2025-12-04T23:53:22.926003Z"
    }
   },
   "outputs": [],
   "source": [
    "present_cols = [col for col in categorical_features if col in train_df.columns]\n",
    " \n",
    "low_cardinality = [col for col in present_cols if train_df[col].nunique() <= 10]\n",
    "high_cardinality = [col for col in present_cols if train_df[col].nunique() > 10]\n",
    "\n",
    "categorical_features = low_cardinality\n",
    "cardinality_features = high_cardinality # excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a91d1e",
   "metadata": {},
   "source": [
    "Çok fazla kategorik özellik var hala. Yapılan diğer çalışmalardan da faydalanarak en çok önemli görülenlerin incelenmesine daha fazla ağırlık verebiliriz.\n",
    "\n",
    "Bu özellikleri konu başlıklarına göre ayırabiliriz.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d5e2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:53:45.707066Z",
     "start_time": "2025-12-04T23:53:45.702064Z"
    }
   },
   "outputs": [],
   "source": [
    "card_features = [col for col in train_df.columns if col.startswith('card')]\n",
    "# resumetable(train_df[card_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90e0fc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:54:17.669252Z",
     "start_time": "2025-12-04T23:54:14.818896Z"
    }
   },
   "outputs": [],
   "source": [
    "# for card3 , <200 -->others\n",
    "valid_card3 = train_df['card3'].value_counts()\n",
    "train_df.loc[train_df['card3'].isin(valid_card3[valid_card3 < 200].index), 'card3'] = \"Others\"\n",
    "\n",
    "# for card5 , <300 --> others \n",
    "valid_card5 = train_df['card5'].value_counts()\n",
    "train_df.loc[train_df['card5'].isin(valid_card5[valid_card5 < 300].index), 'card5'] = \"Others\"\n",
    "\n",
    "train_df = (train_df\n",
    "    .pipe(clean_email_domains)\n",
    "    .pipe(analyze_email_match)\n",
    "    .pipe(consolidate_device_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ba11a6",
   "metadata": {},
   "source": [
    "# Yöntem\n",
    "\n",
    "## Test\n",
    "Chi-Square testi + difference size (max fraud rate - min fraud rate)\n",
    "\n",
    "p-değeri ve difference bizim için anlamlı ise o özelliğin tutulması , yeni eklenecek bir özellik ise eklenmesi anlamlı olacaktır.\n",
    "\n",
    "Alternatif olarak her özelliği ayırıp her biri için Logistic Regression modeli kurmak ve sonucu değerlendirmek olabilir. Ayrıca En güenli ve en riskli alt sınıfların oran farkı yerine Entropy hesaplanabilirdi..\n",
    "\n",
    "Dolandırıcılık gibi durumlarda safsızlık yerine en riskli olanı dikkate almak daha doğru gözüküyor.\n",
    "\n",
    "\n",
    "Sonuçları Görsel olarak da sunmak gereklidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a423e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:55:44.763276Z",
     "start_time": "2025-12-04T23:55:43.571949Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = analyze_time_categories(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b821e9edc6e5b2",
   "metadata": {},
   "source": [
    "cat_binary_test ile şu soruya cevap aranıyor :\n",
    "Elimizdeki kategorik özelliklerin farklı alt sınıfları , isFruad Değişkeninde anlamlı farklar oluşturuyor mu ?\n",
    "\n",
    "Düşük-orta kardinaliteli kategorik feature’ların fraud ile ilişkisini hem istatistiksel hem de pratik açıdan test eder.\n",
    "\n",
    "Basit bir mantığı var ancak anlalı sonuç veriyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94120c95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T23:55:58.944181Z",
     "start_time": "2025-12-04T23:55:57.413175Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_binary_test(train_df , ['DeviceType','ProductCD','card4','card6',\n",
    "                            'M1','M2','M3','M4','M5','M6','id_35'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550c31dd911741",
   "metadata": {},
   "source": [
    "\n",
    "card1 ve card2 özellikleri için dağılım incelenmesi gerekiyor ! sorun çözüldükten sonra eklenmeli !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd2396",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T00:10:27.654132Z",
     "start_time": "2025-12-05T00:10:27.645319Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503da010",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 7))\n",
    "\n",
    "for i, col in enumerate(['card4', 'card6']):\n",
    "    tmp = pd.crosstab(train_df[col], train_df['isFraud'], normalize='index') * 100\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp.rename(columns={1: 'FraudRate', 0: 'NoFraudRate'}, inplace=True)\n",
    "    \n",
    "    # Toplam işlem sayılarını da alalım\n",
    "    total_count = train_df[col].value_counts().reset_index()\n",
    "    total_count.columns = [col, 'Count']\n",
    "    \n",
    "    # Verileri birleştir (Merge)\n",
    "    plot_data = pd.merge(total_count, tmp, on=col)\n",
    "    plot_data = plot_data.sort_values(by='Count', ascending=False) # sort\n",
    "    \n",
    "    # --- 2. Çift Eksenli Grafik Çizimi ---\n",
    "    ax1 = axes[i]\n",
    "    ax2 = ax1.twinx() \n",
    "    \n",
    "    # Bar Plot --> işlem hacmi\n",
    "    sns.barplot(\n",
    "        x=col, \n",
    "        y='Count', \n",
    "        data=plot_data, \n",
    "        ax=ax1, \n",
    "        palette='pastel', \n",
    "        alpha=0.8,\n",
    "        edgecolor='white'\n",
    "    )\n",
    "    \n",
    "    # Line Plot --> fraud yüzdesi\n",
    "    sns.pointplot(\n",
    "        x=col, \n",
    "        y='FraudRate', \n",
    "        data=plot_data, \n",
    "        ax=ax2, \n",
    "        color ='#ff7f50', \n",
    "        markers='o',\n",
    "        scale=0.7 \n",
    "    )\n",
    "    \n",
    "    \n",
    "    ax1.set_title(f'{col} Amount and Fraud Rate', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    \n",
    "    ax1.set_xlabel('Category', fontsize=12)\n",
    "    ax1.set_ylabel('Number of Transactions', fontsize=12, color='gray')\n",
    "    ax2.set_ylabel('Fraud Rate (%)', fontsize=12, color='#ff7f50')\n",
    "    \n",
    "    \n",
    "    ax2.tick_params(axis='y', colors='#ff7f50')\n",
    "    \n",
    "    \n",
    "    ax2.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006c721",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "for i, col in enumerate(['card3', 'card5']):\n",
    "    top_categories = train_df[col].astype(str).value_counts().head(10).index\n",
    "    \n",
    "    plot_data = train_df[train_df[col].astype(str).isin(top_categories)]\n",
    "    \n",
    "\n",
    "    rate_df = plot_data.groupby(col)['isFraud'].mean().reset_index()\n",
    "    rate_df.columns = [col, 'FraudRate']\n",
    "    rate_df['FraudRate'] = rate_df['FraudRate'] * 100 \n",
    "    rate_df = rate_df.sort_values(by='FraudRate', ascending=False)\n",
    "    \n",
    "    sns.barplot(\n",
    "        x=col, \n",
    "        y='FraudRate', \n",
    "        data=rate_df, \n",
    "        palette='pastel', \n",
    "        ax=axes[i],\n",
    "        edgecolor='white'\n",
    "    )\n",
    "    \n",
    "    axes[i].set_title(f'{col} Highest Risk Categories', fontsize=14)\n",
    "    axes[i].set_ylabel('Fraud Rate (%)')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5b60b8",
   "metadata": {},
   "source": [
    "In card5 the most frequent values are 226, 224, 166 that represents 73% of data. Also is posible to see high % of frauds in 137, 147, 141 that has few entries for values.\n",
    "\n",
    "yukaıdaki görselde bu kategorilerin tüme oranı yok sadece risk durumları var."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dee893",
   "metadata": {},
   "source": [
    "\n",
    "##### ProductCD özelliği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical_analysis(train_df,'ProductCD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical_analysis(train_df,'card4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5003c3d",
   "metadata": {},
   "source": [
    "# New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a242a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Unique P_email Count:\", train_df['P_emaildomain'].nunique())\n",
    "print(\"Number of Grouped Unique P_email:\", train_df['P_emaildomain_bin'].nunique())\n",
    "\n",
    "print(\"--- P_emaildomain (Purchaser)---\") # alıcı\n",
    "plot_categorical_analysis(train_df, 'P_emaildomain_bin')\n",
    "\n",
    "print(\"\\n--- R_emaildomain (r-Recipient)---\") # faturayla ilgili\n",
    "plot_categorical_analysis(train_df, 'R_emaildomain_bin')\n",
    "\n",
    "print(\"--- Satın Alan ve Alıcı E-posta Eşleşme ---\")\n",
    "plot_categorical_analysis(train_df, 'email_match')\n",
    "\n",
    "print(\"--- İşletim Sistemi (OS) ---\")\n",
    "plot_categorical_analysis(train_df, 'OS_type')\n",
    "\n",
    "print(\"\\n--- Cihaz Markası (Device) ---\")\n",
    "plot_categorical_analysis(train_df, 'Device_name')\n",
    "\n",
    "\n",
    "print(\"\\n--- Ekran Çözünürlüğü inceleme ---\")\n",
    "analyze_screen_resolution(train_df)\n",
    "\n",
    "# print(\"\\n--- Zamana Bağlı İnceleme ---\")\n",
    "# analyze_time_categories(train_df) yukarı zaten var.\n",
    "\n",
    "print(\"\\n--- M1-M9---\")\n",
    "analyze_m_columns(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390fb66",
   "metadata": {},
   "source": [
    "- P_emaildomain veya R_emaildomain özellikleri proton_mail olması gözlemin çok yüksek ihtimalle dolandırıcı olduğunu gösteriyor.\n",
    "- E-mail eşleşmesi olmaması durumunda dolandırıcılık ihtimalinin artmasını bekliyordum ancak tam tersi durum söz konusu.\n",
    "- OS_Type özelliği incelendiğinde Others sınıfı bilinmeyenleri temsil ediyordu ve en çok dolandırıcılık vakası bu sınıftan çıkmış durumda. Ardından Android geliyor.\n",
    "- Device_name özelliğinden yola çıkarak Bazı markaların kullanıcılarının daha fazla dolandırıcılık vakasına karıştığı görülebiliyor.\n",
    "- Ekran çözünürlüğüne göre Fraud riski sıralandığında özellikle ilk iki sıra ile kalanlar arasında anlamlı bir fark söz konusu.\n",
    "- card4 özelliğinin discover olması daha riskli diyebiliriz.\n",
    "- ProductCD özelliğinin C değeri en riskli sınıf diyebiliriz.\n",
    "- card3 ve card5 özellikleri için bazı değerler fraud ihtimalini arttırabiliyor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc93171",
   "metadata": {},
   "source": [
    "# Bivariate Analysis\n",
    "\n",
    "Kategorik Özelliklerden bazıları ufak düzenlemelerle tek başına dahi gözlemin Fraud olabileceğine dair anlamlı bilgiler veriyor aslında ancak bazı ikili kombinasyonlar sonucunda daha fazla bilgi almayı umuyorum.\n",
    "\n",
    "Instead of manually testing each pair, scan ALL combinations and find the top riskiest ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_to_scan = [\n",
    "    'ProductCD', 'card4', 'card6', \n",
    "    'DeviceType', 'P_emaildomain_bin', 'R_emaildomain_bin',\n",
    "    'email_match', 'OS_type', 'Device_name',\n",
    "    'id_12', 'id_13', 'id_15', 'id_17', 'id_19', 'id_20',\n",
    "    'id_23', 'id_28', 'id_29', 'id_31', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38'\n",
    "]\n",
    "\n",
    "\n",
    "top_combos = scan_all_bivariate_combinations(\n",
    "    train_df, \n",
    "    categorical_to_scan, \n",
    "    min_samples=50,\n",
    "    top_n=50\n",
    ")\n",
    "\n",
    "train_df = create_interaction_features_auto(\n",
    "    train_df, \n",
    "    top_combos, \n",
    "    top_n=15,\n",
    "    min_fraud_rate=20.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(top_combos.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be7b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate_comb_risk(train_df, 'R_emaildomain_bin', 'P_emaildomain_bin' , min_samples= 50).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Oluşturulan Yeni Özellikler:\")\n",
    "display(train_df.created_interaction_features)\n",
    "# display(train_df[train_df.created_interaction_features].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
